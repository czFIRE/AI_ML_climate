{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HztT2r_KeoVf"
      },
      "source": [
        "#  Quantization on pretrained models with using fiftyone for downloading datasets\n",
        "\n",
        "https://voxel51.com/docs/fiftyone/tutorials/evaluate_detections.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxW1EOgPeoVh"
      },
      "source": [
        "## Setup\n",
        "\n",
        "If you haven't already, install FiftyOne:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE8GEvjheoVi",
        "outputId": "68d44976-5897-4ba1-bbf7-24d82f4b9529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.18.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 13.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.4.8)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.0.2)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 134 kB/s \n",
            "\u001b[?25hCollecting mongoengine==0.24.2\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 71.2 MB/s \n",
            "\u001b[?25hCollecting motor>=2.3\n",
            "  Downloading motor-3.1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from fiftyone) (2022.6)\n",
            "Collecting pprintpp\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.3.5)\n",
            "Collecting fiftyone-brain<0.10,>=0.9.2\n",
            "  Downloading fiftyone_brain-0.9.2-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.8.10)\n",
            "Collecting sseclient-py<2,>=1.7.2\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from fiftyone) (6.0)\n",
            "Collecting starlette==0.20.4\n",
            "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiftyone) (57.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.18.3)\n",
            "Requirement already satisfied: pymongo>=3.11 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (4.3.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from fiftyone) (4.6.0.66)\n",
            "Collecting retrying\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Collecting hypercorn>=0.13.2\n",
            "  Downloading Hypercorn-0.14.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting sse-starlette<1,>=0.10.3\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Collecting fiftyone-db<0.5,>=0.4\n",
            "  Downloading fiftyone_db-0.4.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.8 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting dacite>=1.6.0\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting strawberry-graphql==0.138.1\n",
            "  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 67.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (7.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.16.0)\n",
            "Collecting Jinja2>=3\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 65.3 MB/s \n",
            "\u001b[?25hCollecting voxel51-eta<0.9,>=0.8.1\n",
            "  Downloading voxel51_eta-0.8.1-py2.py3-none-any.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 65.9 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.26.14-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 68.2 MB/s \n",
            "\u001b[?25hCollecting ndjson\n",
            "  Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
            "Collecting eventlet\n",
            "  Downloading eventlet-0.33.2-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 68.4 MB/s \n",
            "\u001b[?25hCollecting argcomplete\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fiftyone) (3.2.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fiftyone) (21.3)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.5.0)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.21.6)\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.20.4->fiftyone) (4.1.1)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting backports.cached-property<2.0.0,>=1.0.2\n",
            "  Downloading backports.cached_property-1.0.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (2.10)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from fiftyone-brain<0.10,>=0.9.2->fiftyone) (1.7.3)\n",
            "Collecting typing-extensions>=3.10.0\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
            "Collecting priority\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting h11\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting wsproto>=0.14.0\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting h2>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.14->fiftyone) (1.15.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.14->fiftyone) (8.1.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo>=3.11->fiftyone) (2.2.1)\n",
            "Collecting httpx>=0.10.0\n",
            "  Downloading httpx-0.23.1-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.9.24)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (0.7)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (4.13.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (2.23.0)\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (0.3.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.5.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->voxel51-eta<0.9,>=0.8.1->fiftyone) (3.10.0)\n",
            "Collecting botocore<1.30.0,>=1.29.14\n",
            "  Downloading botocore-1.29.14-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 51.5 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.5 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 66.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.7/dist-packages (from eventlet->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->voxel51-eta<0.9,>=0.8.1->fiftyone) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 62.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2021.11.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.6.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n",
            "Building wheels for collected packages: retrying\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11448 sha256=5449c10a7cd854daccf8901a84232161eab0a41f66b2afa67eeebdc6b0a1c28a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built retrying\n",
            "Installing collected packages: typing-extensions, sniffio, urllib3, rfc3986, jmespath, h11, anyio, hyperframe, httpcore, hpack, botocore, wsproto, starlette, s3transfer, retrying, priority, patool, ndjson, httpx, h2, graphql-core, backports.cached-property, argcomplete, xmltodict, voxel51-eta, universal-analytics-python3, strawberry-graphql, sseclient-py, sse-starlette, pprintpp, motor, mongoengine, kaleido, Jinja2, hypercorn, fiftyone-db, fiftyone-brain, eventlet, Deprecated, dacite, boto3, aiofiles, fiftyone\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.5 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "spacy 3.4.3 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "confection 0.0.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 Jinja2-3.1.2 aiofiles-22.1.0 anyio-3.6.2 argcomplete-2.0.0 backports.cached-property-1.0.2 boto3-1.26.14 botocore-1.29.14 dacite-1.6.0 eventlet-0.33.2 fiftyone-0.18.0 fiftyone-brain-0.9.2 fiftyone-db-0.4.0 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.16.1 httpx-0.23.1 hypercorn-0.14.3 hyperframe-6.0.1 jmespath-1.0.1 kaleido-0.2.1 mongoengine-0.24.2 motor-3.1.1 ndjson-0.3.1 patool-1.12 pprintpp-0.4.0 priority-2.0.0 retrying-1.3.3 rfc3986-1.5.0 s3transfer-0.6.0 sniffio-1.3.0 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.20.4 strawberry-graphql-0.138.1 typing-extensions-4.4.0 universal-analytics-python3-1.1.1 urllib3-1.25.11 voxel51-eta-0.8.1 wsproto-1.2.0 xmltodict-0.13.0\n"
          ]
        }
      ],
      "source": [
        "!pip install fiftyone"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4E-zqR7eoVj"
      },
      "source": [
        "In this tutorial, we'll use an off-the-shelf [Faster R-CNN detection model](https://pytorch.org/docs/stable/torchvision/models.html#faster-r-cnn) provided by PyTorch. To use it, you'll need to install `torch` and `torchvision`, if necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSXgr3THeoVk",
        "outputId": "9a5e8b1c-0d4b-4e38-c2be-bc455785246d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.13.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUCgxMRDeoVl"
      },
      "source": [
        "The following snippet will download the pretrained model from the web and load it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "cb0acf31cc2c4a02907c9ba5c48a92e6",
            "c9ffddea830b4b50b08037ed210b8e23",
            "704273a4c24b494dafc67b3c0855b23b",
            "9a08aab4898c4affba04c8e726077ad4",
            "8d80c4f9dad148b49863eaecb061b55c",
            "c97c8e07ea34457b8cce65887a6e60c3",
            "6c2db484430b4f3e9367094f374fe633",
            "32013ea49f9d433db844be6b1e7abe98",
            "1f362539175f44249ce41f8f97b68568",
            "8ccadd6cc2524212b6a198858997b63a",
            "f379ac058c8e45a39853e4d6bddda309"
          ]
        },
        "id": "ZbFfPX-CeoVl",
        "outputId": "541364e3-3d20-483e-f6a7-693a01e3894e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/ssd300_vgg16_coco-b556d3b4.pth\" to /root/.cache/torch/hub/checkpoints/ssd300_vgg16_coco-b556d3b4.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/136M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb0acf31cc2c4a02907c9ba5c48a92e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model ready\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "# Run the model on GPU if it is available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load a pre-trained Faster R-CNN model\n",
        "#model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "model = torchvision.models.detection.ssd300_vgg16(weights=\"SSD300_VGG16_Weights.COCO_V1\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"Model ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vxnm00bnkgzj",
        "outputId": "0aaeaf7c-7032-48bc-f883-88d884d00305"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29cG_nzFeoVn"
      },
      "source": [
        "We'll perform our analysis on the validation split of the [COCO dataset](https://cocodataset.org/#home), which is conveniently available for download via the [FiftyOne Dataset Zoo](https://voxel51.com/docs/fiftyone/user_guide/dataset_zoo/datasets.html#coco-2017).\n",
        "\n",
        "The snippet below will download the validation split and load it into FiftyOne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXJ_3AE6eoVn",
        "outputId": "8f42c6b1-72d8-4555-cd41-c850b9644251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Migrating database to v0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [8.3s elapsed, 0s remaining, 252.2Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [8.3s elapsed, 0s remaining, 252.2Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    6.1Gb/6.1Gb [24.8s elapsed, 0s remaining, 258.5Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    6.1Gb/6.1Gb [24.8s elapsed, 0s remaining, 258.5Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 5000/5000 [40.9s elapsed, 0s remaining, 139.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 5000/5000 [40.9s elapsed, 0s remaining, 139.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'evaluate-detections-tutorial' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'evaluate-detections-tutorial' created\n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    dataset_name=\"evaluate-detections-tutorial\",\n",
        ")\n",
        "dataset.persistent = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFj5UlhFeoVo"
      },
      "source": [
        "Let's inspect the dataset to see what we downloaded:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEVk7mnieoVp",
        "outputId": "fcdff3f1-f37b-418b-8d14-6f57665c4d68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name:        evaluate-detections-tutorial\n",
            "Media type:  image\n",
            "Num samples: 5000\n",
            "Persistent:  True\n",
            "Tags:        []\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the dataset\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2d_hwSmeoVp",
        "outputId": "43c4b42b-1734-4278-fb6a-25933c0ae8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '637cb2e1429314bebada4cdd',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'potted plant',\n",
            "    'bounding_box': [\n",
            "        0.37028125,\n",
            "        0.3345305164319249,\n",
            "        0.038593749999999996,\n",
            "        0.16314553990610328,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'confidence': None,\n",
            "    'index': None,\n",
            "    'supercategory': 'furniture',\n",
            "    'iscrowd': 0,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Print a ground truth detection\n",
        "sample = dataset.first()\n",
        "print(sample.ground_truth.detections[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLXjVxr2eoVp"
      },
      "source": [
        "Note that the ground truth detections are stored in the `ground_truth` field of the samples.\n",
        "\n",
        "Before we go further, let's launch the [FiftyOne App](https://voxel51.com/docs/fiftyone/user_guide/app.html) and use the GUI to explore the dataset visually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 821
        },
        "id": "OeaSs-z5eoVr",
        "outputId": "90fc5277-614b-4bd5-e4a8-f09fd3d0b798"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "#focontainer-fea00556-3576-4c07-9397-c26ca2d2d770 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-fea00556-3576-4c07-9397-c26ca2d2d770 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-fea00556-3576-4c07-9397-c26ca2d2d770:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-fea00556-3576-4c07-9397-c26ca2d2d770 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-fea00556-3576-4c07-9397-c26ca2d2d770\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-fea00556-3576-4c07-9397-c26ca2d2d770\">\n",
              "      <button id=\"foactivate-fea00556-3576-4c07-9397-c26ca2d2d770\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qyI6mXveoVr"
      },
      "source": [
        "## Add predictions to dataset\n",
        "\n",
        "Now let's generate some predictions to analyze.\n",
        "\n",
        "The code below performs inference with the Faster R-CNN model on a randomly chosen subset of 1000 samples from the dataset and stores the resulting predictions in a `faster_rcnn` field of the samples. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ouwaeEgeeoVr"
      },
      "outputs": [],
      "source": [
        "# Choose a random subset of 1000 samples to add predictions to\n",
        "predictions_view = dataset.take(1000, seed=51)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions_view.first())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwkXcAXDtCpD",
        "outputId": "d0bf57d8-f4c6-4742-a6e8-48e966df7000"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<SampleView: {\n",
            "    'id': '637cb2ed429314bebada76a2',\n",
            "    'media_type': 'image',\n",
            "    'filepath': '/root/fiftyone/coco-2017/validation/data/000000151051.jpg',\n",
            "    'tags': ['validation'],\n",
            "    'metadata': <ImageMetadata: {\n",
            "        'size_bytes': None,\n",
            "        'mime_type': None,\n",
            "        'width': 640,\n",
            "        'height': 478,\n",
            "        'num_channels': None,\n",
            "    }>,\n",
            "    'ground_truth': <Detections: {\n",
            "        'detections': [\n",
            "            <Detection: {\n",
            "                'id': '637cb2ed429314bebada767e',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'person',\n",
            "                'bounding_box': [\n",
            "                    0.20631249999999998,\n",
            "                    0.42043933054393307,\n",
            "                    0.2070625,\n",
            "                    0.2446234309623431,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'person',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "            <Detection: {\n",
            "                'id': '637cb2ed429314bebada767f',\n",
            "                'attributes': {},\n",
            "                'tags': [],\n",
            "                'label': 'skis',\n",
            "                'bounding_box': [\n",
            "                    0.207671875,\n",
            "                    0.694163179916318,\n",
            "                    0.36234375,\n",
            "                    0.17920502092050208,\n",
            "                ],\n",
            "                'mask': None,\n",
            "                'confidence': None,\n",
            "                'index': None,\n",
            "                'supercategory': 'sports',\n",
            "                'iscrowd': 0,\n",
            "            }>,\n",
            "        ],\n",
            "    }>,\n",
            "}>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from torchvision.transforms import functional as func\n",
        "\n",
        "import fiftyone as fo"
      ],
      "metadata": {
        "id": "5BWeVrJHmujl"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIm5Onv0eoVr",
        "outputId": "7c1a2515-6bc3-488b-9443-c94533400e37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [3.1m elapsed, 0s remaining, 5.5 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [3.1m elapsed, 0s remaining, 5.5 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished adding predictions\n"
          ]
        }
      ],
      "source": [
        "# Get class list\n",
        "classes = dataset.default_classes\n",
        "\n",
        "# Add predictions to samples\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(predictions_view):\n",
        "        # Load image\n",
        "        image = Image.open(sample.filepath)\n",
        "        image = func.to_tensor(image).to(device)\n",
        "        c, h, w = image.shape\n",
        "        \n",
        "        # Perform inference\n",
        "        preds = model([image])[0]\n",
        "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
        "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
        "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
        "        \n",
        "        # Convert detections to FiftyOne format\n",
        "        detections = []\n",
        "        for label, score, box in zip(labels, scores, boxes):\n",
        "            # Convert to [top-left-x, top-left-y, width, height]\n",
        "            # in relative coordinates in [0, 1] x [0, 1]\n",
        "            x1, y1, x2, y2 = box\n",
        "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
        "\n",
        "            detections.append(\n",
        "                fo.Detection(\n",
        "                    label=classes[label],\n",
        "                    bounding_box=rel_box,\n",
        "                    confidence=score\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Save predictions to dataset\n",
        "        sample[\"faster_rcnn\"] = fo.Detections(detections=detections)\n",
        "        sample.save()\n",
        "\n",
        "print(\"Finished adding predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3412PE2heoVs"
      },
      "source": [
        "Let's load `predictions_view` in the App to visualize the predictions that we added:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPhc0O04eoVy"
      },
      "source": [
        "### Confidence thresholding in Python\n",
        "\n",
        "FiftyOne also provides the ability to [write expressions](https://voxel51.com/docs/fiftyone/user_guide/using_views.html#filtering) that match, filter, and sort detections based on their attributes. See [using DatasetViews](https://voxel51.com/docs/fiftyone/user_guide/using_views.html) for full details.\n",
        "\n",
        "For example, we can programmatically generate a view that contains only detections whose `confidence` is at least `0.75` as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "73tnFtLjeoVy"
      },
      "outputs": [],
      "source": [
        "from fiftyone import ViewField as F\n",
        "\n",
        "# Only contains detections with confidence >= 0.75\n",
        "high_conf_view = predictions_view.filter_labels(\"faster_rcnn\", F(\"confidence\") > 0.75, only_matches=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0AiJT3geoVz"
      },
      "source": [
        "Note the `only_matches=False` argument. When filtering labels, any samples that no longer contain labels would normally be removed from the view. However, this is not desired when performing evaluations since it can skew your results between views. We set `only_matches=False` so that all samples will be retained, even if some no longer contain labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8s_s6bpOeoVz",
        "outputId": "e8172516-8a11-47d7-b068-20e6781e15a1",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     evaluate-detections-tutorial\n",
            "Media type:  image\n",
            "Num samples: 1000\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    faster_rcnn:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "View stages:\n",
            "    1. Take(size=1000, seed=51)\n",
            "    2. FilterLabels(field='faster_rcnn', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "# Print some information about the view\n",
        "print(high_conf_view)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzP_f1qLeoVz",
        "outputId": "3a0ba541-6df5-4173-9f82-cc2e084ad984",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Detection: {\n",
            "    'id': '637cb318429314bebadaf012',\n",
            "    'attributes': {},\n",
            "    'tags': [],\n",
            "    'label': 'person',\n",
            "    'bounding_box': [\n",
            "        0.20957474708557128,\n",
            "        0.4165088541836918,\n",
            "        0.207650089263916,\n",
            "        0.27272866859595646,\n",
            "    ],\n",
            "    'mask': None,\n",
            "    'confidence': 0.9438897967338562,\n",
            "    'index': None,\n",
            "}>\n"
          ]
        }
      ],
      "source": [
        "# Print a prediction from the view to verify that its confidence is > 0.75\n",
        "sample = high_conf_view.first()\n",
        "print(sample.faster_rcnn.detections[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJQgbn2GeoV0"
      },
      "source": [
        "Now let's load our view in the App to view the predictions that we programmatically selected:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO0PlwOdeoV1"
      },
      "source": [
        "## Evaluate detections\n",
        "\n",
        "Now that we have samples with ground truth and predicted objects, let's use FiftyOne to evaluate the quality of the detections.\n",
        "\n",
        "FiftyOne provides a powerful [evaluation API](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html) that contains a collection of methods for performing evaluation of model predictions. Since we're working with object detections here, we'll use [detection evaluation](https://voxel51.com/docs/fiftyone/user_guide/evaluation.html#detections)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtETueAEeoV1"
      },
      "source": [
        "### Running evaluation\n",
        "\n",
        "We can run evaluation on our samples via [evaluate_detections()](https://voxel51.com/docs/fiftyone/api/fiftyone.core.collections.html#fiftyone.core.collections.SampleCollection.evaluate_detections). Note that this method is available on both the `Dataset` and `DatasetView` classes, which means that we can run evaluation on our `high_conf_view` to assess the quality of only the high confidence predictions in our dataset.\n",
        "\n",
        "By default, this method will use the [COCO evaluation protocol](https://cocodataset.org/#detection-eval), plus some extra goodies that we will use later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBABJlpFeoV2",
        "outputId": "aff2bf57-2c2f-4544-89a4-770de04a1840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [27.3s elapsed, 0s remaining, 37.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [27.3s elapsed, 0s remaining, 37.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [14.4s elapsed, 0s remaining, 66.6 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [14.4s elapsed, 0s remaining, 66.6 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "# Evaluate the predictions in the `faster_rcnn` field of our `high_conf_view`\n",
        "# with respect to the objects in the `ground_truth` field\n",
        "results = high_conf_view.evaluate_detections(\n",
        "    \"faster_rcnn\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VosnnZROeoV2"
      },
      "source": [
        "### Aggregate results\n",
        "\n",
        "The `results` object returned by the evaluation routine provides a number of convenient methods for analyzing our predictions.\n",
        "\n",
        "For example, let's print a classification report for the top-10 most common classes in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6TWfWxWeoV2",
        "outputId": "716b7e5a-fb0d-484a-fbb1-de8304dc16a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       0.98      0.28      0.43      2176\n",
            "          car       0.96      0.12      0.21       457\n",
            "        chair       0.87      0.09      0.16       304\n",
            "         book       1.00      0.00      0.01       283\n",
            "       bottle       0.71      0.03      0.05       187\n",
            "          cup       0.95      0.09      0.16       222\n",
            " dining table       0.71      0.12      0.20       127\n",
            "traffic light       1.00      0.03      0.05       116\n",
            "         bowl       0.70      0.06      0.11       119\n",
            "      handbag       0.00      0.00      0.00        95\n",
            "\n",
            "    micro avg       0.96      0.18      0.30      4086\n",
            "    macro avg       0.79      0.08      0.14      4086\n",
            " weighted avg       0.92      0.18      0.29      4086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 classes\n",
        "results.print_report(classes=classes_top10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAa9dyo6eoV3"
      },
      "source": [
        "We can also compute the mean average-precision (mAP) of our detector:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oSQZJtKeoV3",
        "outputId": "a6d53292-c04e-4892-db49-a721ce226401"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14640761435595998\n"
          ]
        }
      ],
      "source": [
        "print(results.mAP())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlVIQd62eoV3"
      },
      "source": [
        "Since [evaluate_detections()](https://voxel51.com/docs/fiftyone/api/fiftyone.core.collections.html#fiftyone.core.collections.SampleCollection.evaluate_detections) uses the official [COCO evaluation protocol](https://cocodataset.org/#detection-eval), this mAP value will match what `pycocotools` would report.\n",
        "\n",
        "We can also view some precision-recall (PR) curves for specific classes of our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "D1GMmUAjeoV4",
        "outputId": "e0dc3da3-4ab2-4a07-d9bb-a29601573246"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"70cc984a-93d4-4b08-94fb-4363ae904934\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"70cc984a-93d4-4b08-94fb-4363ae904934\")) {                    Plotly.newPlot(                        \"70cc984a-93d4-4b08-94fb-4363ae904934\",                        [{\"customdata\":[0.999994158744812,0.998924845457077,0.8989129185676574,0.8979243278503418,0.896625405550003,0.8949989795684814,0.8921549201011658,0.8881390511989593,0.8785696804523468,0.8638964474201203,0.7835114598274231,0.7770073354244232,0.7705133140087128,0.7628681540489197,0.7529365479946136,0.7392556071281433,0.6536208868026734,0.6445655941963195,0.633165693283081,0.6212004721164703,0.606891930103302,0.5203230321407318,0.5093582689762115,0.49713889956474305,0.4103007435798645,0.39931645393371584,0.31257829666137693,0.2288152575492859,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"<b>class: %{text}</b><br>recall: %{x:.3f}<br>precision: %{y:.3f}<br>threshold: %{customdata:.3f}<extra></extra>\",\"line\":{\"color\":\"#3366CC\"},\"mode\":\"lines\",\"name\":\"person (AP = 0.191)\",\"text\":[\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\",\"person\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[0.9169230769230771,0.8787274575451915,0.8462604771115408,0.843764021580923,0.8407483786055214,0.8298555522396954,0.8226367613510005,0.8050568444470858,0.7910641089077506,0.7828125911361989,0.7473194940687258,0.7403197408493372,0.7332379882563663,0.7296771269889211,0.7206939700922121,0.7154082267072184,0.6560442724594511,0.652481816662877,0.6478269902980663,0.6432685601592606,0.6402814668116719,0.5665652878941334,0.5639416339553962,0.5612539279156635,0.475983238664461,0.47506114993503773,0.3841662206363366,0.2904322063436737,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"},{\"customdata\":[0.9960059523582458,0.8910532891750336,0.8779930651187897,0.8702674567699432,0.844853687286377,0.8309709370136261,0.7307459890842438,0.7194898784160614,0.6171205580234528,0.5971805334091187,0.5639927506446838,0.38573881387710574,0.07574808001518249,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"hovertemplate\":\"<b>class: %{text}</b><br>recall: %{x:.3f}<br>precision: %{y:.3f}<br>threshold: %{customdata:.3f}<extra></extra>\",\"line\":{\"color\":\"#DC3912\"},\"mode\":\"lines\",\"name\":\"car (AP = 0.089)\",\"text\":[\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\",\"car\"],\"x\":[0.0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08,0.09,0.1,0.11,0.12,0.13,0.14,0.15,0.16,0.17,0.18,0.19,0.2,0.21,0.22,0.23,0.24,0.25,0.26,0.27,0.28,0.29,0.3,0.31,0.32,0.33,0.34,0.35000000000000003,0.36,0.37,0.38,0.39,0.4,0.41000000000000003,0.42,0.43,0.44,0.45,0.46,0.47000000000000003,0.48,0.49,0.5,0.51,0.52,0.53,0.54,0.55,0.56,0.5700000000000001,0.58,0.59,0.6,0.61,0.62,0.63,0.64,0.65,0.66,0.67,0.68,0.6900000000000001,0.7000000000000001,0.71,0.72,0.73,0.74,0.75,0.76,0.77,0.78,0.79,0.8,0.81,0.8200000000000001,0.8300000000000001,0.84,0.85,0.86,0.87,0.88,0.89,0.9,0.91,0.92,0.93,0.9400000000000001,0.9500000000000001,0.96,0.97,0.98,0.99,1.0],\"y\":[0.9099999999999999,0.8714285714285713,0.8349875930521092,0.8037917888563049,0.8009904306220095,0.794022417299013,0.745086247086247,0.7382056277056277,0.6673722943722944,0.6593636363636364,0.6449122807017544,0.4627606752730884,0.09649122807017543,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0],\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(51,51,51)\"},\"error_y\":{\"color\":\"rgb(51,51,51)\"},\"marker\":{\"line\":{\"color\":\"rgb(237,237,237)\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"baxis\":{\"endlinecolor\":\"rgb(51,51,51)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(51,51,51)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"},\"colorscale\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"tickcolor\":\"rgb(237,237,237)\",\"ticklen\":6,\"ticks\":\"inside\"}},\"colorscale\":{\"sequential\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]],\"sequentialminus\":[[0,\"rgb(20,44,66)\"],[1,\"rgb(90,179,244)\"]]},\"colorway\":[\"#F8766D\",\"#A3A500\",\"#00BF7D\",\"#00B0F6\",\"#E76BF3\"],\"font\":{\"color\":\"rgb(51,51,51)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"rgb(237,237,237)\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"rgb(237,237,237)\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"rgb(237,237,237)\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"},\"bgcolor\":\"rgb(237,237,237)\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\"}},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showgrid\":true,\"tickcolor\":\"rgb(51,51,51)\",\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\"}}},\"shapes\":[{\"line\":{\"dash\":\"dash\"},\"type\":\"line\",\"x0\":0,\"x1\":1,\"y0\":1,\"y1\":0}],\"xaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"title\":{\"text\":\"Recall\"}},\"yaxis\":{\"range\":[0,1],\"constrain\":\"domain\",\"scaleanchor\":\"x\",\"scaleratio\":1,\"title\":{\"text\":\"Precision\"}},\"title\":{},\"margin\":{\"r\":0,\"t\":30,\"l\":0,\"b\":0}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('70cc984a-93d4-4b08-94fb-4363ae904934');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot = results.plot_pr_curves(classes=[\"person\", \"car\"])\n",
        "plot.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIS04DS2l4XU",
        "outputId": "fe3b7465-2f93-4bbc-ac0b-0e64010ac58a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSD(\n",
            "  (backbone): SSDFeatureExtractorVGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (18): ReLU(inplace=True)\n",
            "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "    )\n",
            "    (extra): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (6): ReLU(inplace=True)\n",
            "        (7): Sequential(\n",
            "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "          (4): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
            "  (head): SSDHead(\n",
            "    (classification_head): SSDClassificationHead(\n",
            "      (module_list): ModuleList(\n",
            "        (0): Conv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): Conv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (2): Conv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): Conv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): Conv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (regression_head): SSDRegressionHead(\n",
            "      (module_list): ModuleList(\n",
            "        (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (transform): GeneralizedRCNNTransform(\n",
            "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
            "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-hs57uXm7TW",
        "outputId": "cc6fc070-9b4e-4103-f8c2-5a85aab1a48a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 142.592912\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "def print_size_of_model(model_):\n",
        "    \"\"\" Prints the real size of the model \"\"\"\n",
        "    torch.save(model_.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')\n",
        "\n",
        "print_size_of_model(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPqlkOjquyes"
      },
      "source": [
        "Problem with quantization in Torch is that Torch doesn't know how to change dtype of Conv2D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "vRtmm4afzOSK"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "orig_model = copy.deepcopy(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXDzzIgpk5dp"
      },
      "source": [
        "## FP16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8On9pizUqUVk",
        "outputId": "4b164051-0cf9-4fc4-a26b-b8b378e1b69d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, weight=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric){})\n"
          ]
        }
      ],
      "source": [
        "import torch.quantization\n",
        "from torch.quantization import QuantStub, DeQuantStub\n",
        "\n",
        "print(torch.quantization.default_qconfig)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model = copy.deepcopy(orig_model)\n",
        "model.eval()\n",
        "\n",
        "# Fuse Conv, bn and relu\n",
        "#myModel.fuse_model()\n",
        "\n",
        "#torch.quantization.fuse_modules(model, inplace=True)\n",
        "\n",
        "#model_int8 = torch.nn.Sequential(torch.quantization.QuantStub(), model, torch.quantization.DeQuantStub())\n",
        "model_fp16 = torch.quantization.QuantWrapper(model)\n",
        "\n",
        "# Specify quantization configuration\n",
        "# Start with simple min/max range estimation and per-tensor quantization of weights\n",
        "#model_fp16.qconfig = torch.ao.quantization.default_qconfig\n",
        "\n",
        "model_fp16.qconfig = torch.ao.quantization.QConfig(\n",
        "    activation=torch.ao.quantization.observer.MinMaxObserver.with_args(dtype=torch.qint8),\n",
        "    weight=torch.ao.quantization.observer.default_observer.with_args(dtype=torch.qint8))\n",
        "\n",
        "print(model_fp16.qconfig)\n",
        "torch.ao.quantization.prepare(model_fp16, inplace=True)\n",
        "\n",
        "with torch.inference_mode():\n",
        "  for _ in range(10):\n",
        "    x = torch.rand(1,3, 640, 478).to(device)\n",
        "    model_fp16(x)\n",
        "\n",
        "# Convert to quantized model\n",
        "torch.ao.quantization.convert(model_fp16, inplace=True)\n",
        "\"\"\"\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "InwxTCcJq4II",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4660d23b-6c40-4090-9c42-17f2da3992a9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VYadQXyk49n",
        "outputId": "57e140f7-8ab5-41db-bbd7-79ab051a266a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 71.309264\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "model_fp16 = torch.quantization.quantize_dynamic(\n",
        "    model,  # the original model\n",
        "    {torch.nn.Linear, torch.nn.Conv2d},  # a set of layers to dynamically quantize\n",
        "    dtype=torch.float16\n",
        ")  # the target dtype for quantized weights\n",
        "\"\"\"\n",
        "\n",
        "model_fp16 = copy.deepcopy(orig_model).type(torch.float16)\n",
        "\n",
        "print_size_of_model(model_fp16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "5Cfnqlcxro7R"
      },
      "outputs": [],
      "source": [
        "#predictions_view = dataset.take(1000, seed=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PTIE8EMbsBhZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7466416d-8e74-4c9b-87e4-b17812f62648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [4.1m elapsed, 0s remaining, 4.2 samples/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [4.1m elapsed, 0s remaining, 4.2 samples/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished adding predictions\n"
          ]
        }
      ],
      "source": [
        "# Get class list\n",
        "classes = dataset.default_classes\n",
        "\n",
        "# Add predictions to samples\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(predictions_view):\n",
        "        # Load image\n",
        "        image = Image.open(sample.filepath)\n",
        "        image = func.to_tensor(image).to(device).to(torch.float16)\n",
        "        c, h, w = image.shape\n",
        "        \n",
        "        # Perform inference\n",
        "        preds = model_fp16([image])[0]\n",
        "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
        "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
        "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
        "        \n",
        "        # Convert detections to FiftyOne format\n",
        "        detections = []\n",
        "        for label, score, box in zip(labels, scores, boxes):\n",
        "            # Convert to [top-left-x, top-left-y, width, height]\n",
        "            # in relative coordinates in [0, 1] x [0, 1]\n",
        "            x1, y1, x2, y2 = box\n",
        "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
        "\n",
        "            detections.append(\n",
        "                fo.Detection(\n",
        "                    label=classes[label],\n",
        "                    bounding_box=rel_box,\n",
        "                    confidence=score\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Save predictions to dataset\n",
        "        sample[\"faster_rcnn\"] = fo.Detections(detections=detections)\n",
        "        sample.save()\n",
        "\n",
        "print(\"Finished adding predictions\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "LXdE5F6csRFV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d65793c3-008c-4121-c1ec-db9b173f66c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     evaluate-detections-tutorial\n",
            "Media type:  image\n",
            "Num samples: 1000\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    faster_rcnn:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:      fiftyone.core.fields.IntField\n",
            "    eval_fp:      fiftyone.core.fields.IntField\n",
            "    eval_fn:      fiftyone.core.fields.IntField\n",
            "View stages:\n",
            "    1. Take(size=1000, seed=51)\n",
            "    2. FilterLabels(field='faster_rcnn', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "high_conf_view_fp16 = predictions_view.filter_labels(\"faster_rcnn\", F(\"confidence\") > 0.75, only_matches=False)\n",
        "print(high_conf_view_fp16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JchcinDose4Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68e52a0-d25f-4c22-af1e-2b4928eedc0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [24.6s elapsed, 0s remaining, 37.7 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [24.6s elapsed, 0s remaining, 37.7 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [14.3s elapsed, 0s remaining, 67.9 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [14.3s elapsed, 0s remaining, 67.9 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "results_fp16 = high_conf_view_fp16.evaluate_detections(\n",
        "    \"faster_rcnn\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9G2QYHN1spFT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2c918d8-c86c-45a4-ae14-cefc14e7fe0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       0.98      0.28      0.43      2175\n",
            "          car       0.96      0.12      0.21       457\n",
            "        chair       0.87      0.09      0.16       304\n",
            "         book       1.00      0.00      0.01       283\n",
            "       bottle       0.71      0.03      0.05       187\n",
            "          cup       0.95      0.09      0.16       222\n",
            " dining table       0.75      0.12      0.20       127\n",
            "traffic light       1.00      0.03      0.05       116\n",
            "         bowl       0.70      0.06      0.11       119\n",
            "      handbag       0.00      0.00      0.00        95\n",
            "\n",
            "    micro avg       0.96      0.18      0.30      4085\n",
            "    macro avg       0.79      0.08      0.14      4085\n",
            " weighted avg       0.92      0.18      0.29      4085\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 classes\n",
        "results_fp16.print_report(classes=classes_top10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "DgD-U9FPsppl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553427ac-6ef1-4a3b-a7f8-bf165b7a7956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14625477027883566\n"
          ]
        }
      ],
      "source": [
        "print(results_fp16.mAP())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbfser4jrpKq"
      },
      "source": [
        "## INT8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "per_channel_quantized_model = copy.deepcopy(orig_model)\n",
        "per_channel_quantized_model.eval()\n",
        "#per_channel_quantized_model.fuse_model()\n",
        "per_channel_quantized_model.qconfig = torch.ao.quantization.get_default_qconfig('fbgemm')\n",
        "print(per_channel_quantized_model.qconfig)\n",
        "\n",
        "torch.ao.quantization.prepare(per_channel_quantized_model, inplace=True)\n",
        "\n",
        "torch.ao.quantization.convert(per_channel_quantized_model, inplace=True)\n",
        "\n",
        "print(\"\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "B68vsiTRwcQ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0036aa42-be67-4712-cde6-72646cd6eece"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nper_channel_quantized_model = copy.deepcopy(orig_model)\\nper_channel_quantized_model.eval()\\n#per_channel_quantized_model.fuse_model()\\nper_channel_quantized_model.qconfig = torch.ao.quantization.get_default_qconfig(\\'fbgemm\\')\\nprint(per_channel_quantized_model.qconfig)\\n\\ntorch.ao.quantization.prepare(per_channel_quantized_model, inplace=True)\\n\\ntorch.ao.quantization.convert(per_channel_quantized_model, inplace=True)\\n\\nprint(\"\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "model_int8 = copy.deepcopy(orig_model)\n",
        "\n",
        "model_int8.eval().to('cpu')\n",
        "#model_int8.fuse_model()\n",
        "model_int8.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
        "torch.quantization.prepare(model_int8, inplace=True)\n",
        "torch.quantization.convert(model_int8, inplace=True)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NN5oCzCGVuoD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fae7625b-02be-4eb3-d135-4e69a1f510b1"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmodel_int8 = copy.deepcopy(orig_model)\\n\\nmodel_int8.eval().to('cpu')\\n#model_int8.fuse_model()\\nmodel_int8.qconfig = torch.quantization.get_default_qconfig('fbgemm')\\ntorch.quantization.prepare(model_int8, inplace=True)\\ntorch.quantization.convert(model_int8, inplace=True)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = copy.deepcopy(orig_model)\n",
        "model.eval()\n",
        "\n",
        "# Fuse Conv, bn and relu\n",
        "#myModel.fuse_model()\n",
        "\n",
        "#torch.quantization.fuse_modules(model, inplace=True)\n",
        "\n",
        "#model_int8 = torch.nn.Sequential(torch.quantization.QuantStub(), model, torch.quantization.DeQuantStub())\n",
        "model_int8 = torch.quantization.QuantWrapper(model)\n",
        "\n",
        "# Specify quantization configuration\n",
        "# Start with simple min/max range estimation and per-tensor quantization of weights\n",
        "#model_int8.qconfig = torch.ao.quantization.default_qconfig\n",
        "\n",
        "model_int8.qconfig = torch.ao.quantization.QConfig(\n",
        "    activation=torch.ao.quantization.observer.MinMaxObserver.with_args(dtype=torch.qint8),\n",
        "    weight=torch.ao.quantization.observer.default_observer.with_args(dtype=torch.qint8))\n",
        "\n",
        "print(model_int8.qconfig)\n",
        "torch.ao.quantization.prepare(model_int8, inplace=True)\n",
        "\n",
        "with torch.inference_mode():\n",
        "  for _ in range(10):\n",
        "    x = torch.rand(1,3, 640, 478).to(device)\n",
        "    model_int8(x)\n",
        "\n",
        "# Convert to quantized model\n",
        "torch.ao.quantization.convert(model_int8, inplace=True)\n",
        "\n",
        "print(\"\")"
      ],
      "metadata": {
        "id": "QoxoCFvtvFqR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a69966bd-9ff6-4418-edc4-c6c5d1b85f0c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "QConfig(activation=functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, dtype=torch.qint8){}, weight=functools.partial(functools.partial(<class 'torch.ao.quantization.observer.MinMaxObserver'>, quant_min=0, quant_max=127){}, dtype=torch.qint8){})\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "x = torch.rand(1,3, 640, 478).to(\"cpu\")\n",
        "print(x)\n",
        "model_int8 = model_int8.type(torch.int8)\n",
        "model_int8(x)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "absOgnNnRJXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ac1b18d5-6a2e-4dba-82ae-ff18caf50c66"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nx = torch.rand(1,3, 640, 478).to(\"cpu\")\\nprint(x)\\nmodel_int8 = model_int8.type(torch.int8)\\nmodel_int8(x)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import functools\n",
        "\n",
        "conf = torch.ao.quantization.default_qconfig\n",
        "print(conf)\n",
        "\n",
        "#conf.activation = functools.partial(torch.ao.quantization.observer.MinMaxObserver, quant_min=0, quant_max=255)\n",
        "print(torch.ao.quantization.QConfig(\n",
        "    activation=torch.ao.quantization.observer.MinMaxObserver.with_args(dtype=torch.qint8),\n",
        "    weight=torch.ao.quantization.observer.default_observer.with_args(dtype=torch.qint8)))\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NZ3dTPph_Vnj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c35fe23a-d2bb-4a11-bcf8-aaa140cb2ad3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport functools\\n\\nconf = torch.ao.quantization.default_qconfig\\nprint(conf)\\n\\n#conf.activation = functools.partial(torch.ao.quantization.observer.MinMaxObserver, quant_min=0, quant_max=255)\\nprint(torch.ao.quantization.QConfig(\\n    activation=torch.ao.quantization.observer.MinMaxObserver.with_args(dtype=torch.qint8),\\n    weight=torch.ao.quantization.observer.default_observer.with_args(dtype=torch.qint8)))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "from torch.quantization import quantize_fx\n",
        "m = copy.deepcopy(orig_model)\n",
        "m.eval()\n",
        "qconfig_dict = {\"\": torch.quantization.get_default_qconfig(\"fbgemm\")}\n",
        "# Prepare\n",
        "model_prepared = quantize_fx.prepare_fx(m, qconfig_dict)\n",
        "# Calibrate - Use representative (validation) data.\n",
        "\n",
        "model_int8 = quantize_fx.convert_fx(model_prepared)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "tssymgEX2qjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bc01e419-06a9-40bd-b797-67404a7187ce"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom torch.quantization import quantize_fx\\nm = copy.deepcopy(orig_model)\\nm.eval()\\nqconfig_dict = {\"\": torch.quantization.get_default_qconfig(\"fbgemm\")}\\n# Prepare\\nmodel_prepared = quantize_fx.prepare_fx(m, qconfig_dict)\\n# Calibrate - Use representative (validation) data.\\n\\nmodel_int8 = quantize_fx.convert_fx(model_prepared)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_int8 = torch.quantization.quantize_dynamic(\n",
        "    orig_model,  # the original model\n",
        "    {torch.nn.Linear, torch.nn.Conv2d},  # a set of layers to dynamically quantize\n",
        "    dtype=torch.qint8)"
      ],
      "metadata": {
        "id": "rwe4vORGjil4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_size_of_model(model_int8)"
      ],
      "metadata": {
        "id": "uiPWv4DUpNPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c130cadf-a697-4f45-8d16-a9c1bbc624d2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size (MB): 142.592912\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the model is quantised in the code representation, however it still doesn't work.\n",
        "\n",
        "The size should be around 37 MB"
      ],
      "metadata": {
        "id": "xQhu6vW4JDBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "a9JfDWo3jZQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a996c14f-b7d9-48d4-844e-dd15161a7e2a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SSD(\n",
            "  (backbone): SSDFeatureExtractorVGG(\n",
            "    (features): Sequential(\n",
            "      (0): QuantizedConv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), scale=3.4091553688049316, zero_point=-3, padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): QuantizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), scale=11.399210929870605, zero_point=-12, padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): QuantizedConv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), scale=27.139928817749023, zero_point=32, padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): QuantizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), scale=31.4085693359375, zero_point=6, padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=29.787199020385742, zero_point=31, padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=15.580648422241211, zero_point=10, padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): QuantizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), scale=10.04648494720459, zero_point=-11, padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
            "      (17): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), scale=4.628392696380615, zero_point=-11, padding=(1, 1))\n",
            "      (18): ReLU(inplace=True)\n",
            "      (19): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=2.1436045169830322, zero_point=1, padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=1.0550036430358887, zero_point=8, padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "    )\n",
            "    (extra): ModuleList(\n",
            "      (0): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.4113284647464752, zero_point=-1, padding=(1, 1))\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.1447160392999649, zero_point=6, padding=(1, 1))\n",
            "        (4): ReLU(inplace=True)\n",
            "        (5): QuantizedConv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), scale=0.0792132019996643, zero_point=0, padding=(1, 1))\n",
            "        (6): ReLU(inplace=True)\n",
            "        (7): Sequential(\n",
            "          (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
            "          (1): QuantizedConv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), scale=0.035239219665527344, zero_point=-18, padding=(6, 6), dilation=(6, 6))\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): QuantizedConv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), scale=0.016014771535992622, zero_point=-31)\n",
            "          (4): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Sequential(\n",
            "        (0): QuantizedConv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), scale=0.019970322027802467, zero_point=-26)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): QuantizedConv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), scale=0.03206802159547806, zero_point=-6, padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Sequential(\n",
            "        (0): QuantizedConv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.03137500211596489, zero_point=-77)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), scale=0.04906235635280609, zero_point=22, padding=(1, 1))\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Sequential(\n",
            "        (0): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.03139810636639595, zero_point=-57)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.048763588070869446, zero_point=11)\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Sequential(\n",
            "        (0): QuantizedConv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), scale=0.029453640803694725, zero_point=-110)\n",
            "        (1): ReLU(inplace=True)\n",
            "        (2): QuantizedConv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), scale=0.0512133426964283, zero_point=-72)\n",
            "        (3): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (anchor_generator): DefaultBoxGenerator(aspect_ratios=[[2], [2, 3], [2, 3], [2, 3], [2], [2]], clip=True, scales=[0.07, 0.15, 0.33, 0.51, 0.69, 0.87, 1.05], steps=[8, 16, 32, 64, 100, 300])\n",
            "  (head): SSDHead(\n",
            "    (classification_head): SSDClassificationHead(\n",
            "      (module_list): ModuleList(\n",
            "        (0): QuantizedConv2d(512, 364, kernel_size=(3, 3), stride=(1, 1), scale=0.04002373293042183, zero_point=-93, padding=(1, 1))\n",
            "        (1): QuantizedConv2d(1024, 546, kernel_size=(3, 3), stride=(1, 1), scale=0.04855678230524063, zero_point=-63, padding=(1, 1))\n",
            "        (2): QuantizedConv2d(512, 546, kernel_size=(3, 3), stride=(1, 1), scale=0.048300813883543015, zero_point=-60, padding=(1, 1))\n",
            "        (3): QuantizedConv2d(256, 546, kernel_size=(3, 3), stride=(1, 1), scale=0.049855343997478485, zero_point=-48, padding=(1, 1))\n",
            "        (4): QuantizedConv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), scale=0.05327436327934265, zero_point=-43, padding=(1, 1))\n",
            "        (5): QuantizedConv2d(256, 364, kernel_size=(3, 3), stride=(1, 1), scale=0.04444320499897003, zero_point=-33, padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "    (regression_head): SSDRegressionHead(\n",
            "      (module_list): ModuleList(\n",
            "        (0): QuantizedConv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.06410855799913406, zero_point=68, padding=(1, 1))\n",
            "        (1): QuantizedConv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), scale=0.01423067320138216, zero_point=26, padding=(1, 1))\n",
            "        (2): QuantizedConv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), scale=0.024821950122714043, zero_point=40, padding=(1, 1))\n",
            "        (3): QuantizedConv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), scale=0.020063944160938263, zero_point=4, padding=(1, 1))\n",
            "        (4): QuantizedConv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.019896240904927254, zero_point=-34, padding=(1, 1))\n",
            "        (5): QuantizedConv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), scale=0.009969090111553669, zero_point=-109, padding=(1, 1))\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (transform): GeneralizedRCNNTransform(\n",
            "      Normalize(mean=[0.48235, 0.45882, 0.40784], std=[0.00392156862745098, 0.00392156862745098, 0.00392156862745098])\n",
            "      Resize(min_size=(300,), max_size=300, mode='bilinear')\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UlnjZDDHr6UR"
      },
      "outputs": [],
      "source": [
        "#predictions_view = dataset.take(1000, seed=52)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bjy8eHFhsCXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b768b77-ac91-4c05-b4de-2d9668ca1b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [4.7m elapsed, 0s remaining, 4.1 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [4.7m elapsed, 0s remaining, 4.1 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finished adding predictions\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get class list\n",
        "classes = dataset.default_classes\n",
        "\n",
        "\n",
        "# Add predictions to samples\n",
        "with fo.ProgressBar() as pb:\n",
        "    for sample in pb(predictions_view):\n",
        "        # Load image\n",
        "        image = Image.open(sample.filepath)\n",
        "        #image = (func.to_tensor(image).to(device)*255).to(torch.int8)\n",
        "        image = func.to_tensor(image).to(device)\n",
        "        \n",
        "        #print(image)\n",
        "        #print(type(image))\n",
        "        #print(image.shape)\n",
        "\n",
        "        c, h, w = image.shape\n",
        "\n",
        "        images = torch.stack([image])\n",
        "        #print(images)\n",
        "        \n",
        "        # Perform inference\n",
        "        preds = model_int8(images)[0]\n",
        "        labels = preds[\"labels\"].cpu().detach().numpy()\n",
        "        scores = preds[\"scores\"].cpu().detach().numpy()\n",
        "        boxes = preds[\"boxes\"].cpu().detach().numpy()\n",
        "        \n",
        "        # Convert detections to FiftyOne format\n",
        "        detections = []\n",
        "        for label, score, box in zip(labels, scores, boxes):\n",
        "            # Convert to [top-left-x, top-left-y, width, height]\n",
        "            # in relative coordinates in [0, 1] x [0, 1]\n",
        "            x1, y1, x2, y2 = box\n",
        "            rel_box = [x1 / w, y1 / h, (x2 - x1) / w, (y2 - y1) / h]\n",
        "\n",
        "            detections.append(\n",
        "                fo.Detection(\n",
        "                    label=classes[label],\n",
        "                    bounding_box=rel_box,\n",
        "                    confidence=score\n",
        "                )\n",
        "            )\n",
        "        \n",
        "        # Save predictions to dataset\n",
        "        sample[\"faster_rcnn\"] = fo.Detections(detections=detections)\n",
        "        sample.save()\n",
        "\n",
        "print(\"Finished adding predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We expected the runtime to decrease to around 1.3 minutes, however due to some bugs in Pytorch we were unable to get to this."
      ],
      "metadata": {
        "id": "8V1oWxqbK6fm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "1RoM5ailsiiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d374b9c2-8df3-4af6-e6c8-fa332189deca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset:     evaluate-detections-tutorial\n",
            "Media type:  image\n",
            "Num samples: 1000\n",
            "Sample fields:\n",
            "    id:           fiftyone.core.fields.ObjectIdField\n",
            "    filepath:     fiftyone.core.fields.StringField\n",
            "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
            "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    faster_rcnn:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    eval_tp:      fiftyone.core.fields.IntField\n",
            "    eval_fp:      fiftyone.core.fields.IntField\n",
            "    eval_fn:      fiftyone.core.fields.IntField\n",
            "View stages:\n",
            "    1. Take(size=1000, seed=51)\n",
            "    2. FilterLabels(field='faster_rcnn', filter={'$gt': ['$$this.confidence', 0.75]}, only_matches=False, trajectories=False)\n"
          ]
        }
      ],
      "source": [
        "high_conf_view_int8 = predictions_view.filter_labels(\"faster_rcnn\", F(\"confidence\") > 0.75, only_matches=False)\n",
        "print(high_conf_view_int8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "g0RhwCjwsirz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5937cab-cabc-48b8-bda9-dfc6de6e644e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.detection:Evaluating detections...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [27.0s elapsed, 0s remaining, 38.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [27.0s elapsed, 0s remaining, 38.4 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.eval.coco:Performing IoU sweep...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 1000/1000 [14.4s elapsed, 0s remaining, 66.2 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 1000/1000 [14.4s elapsed, 0s remaining, 66.2 samples/s]      \n"
          ]
        }
      ],
      "source": [
        "results_int8 = high_conf_view_int8.evaluate_detections(\n",
        "    \"faster_rcnn\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    eval_key=\"eval\",\n",
        "    compute_mAP=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "oVZdzISHstdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4499f28-1efe-45f0-fc95-5899612e3f91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               precision    recall  f1-score   support\n",
            "\n",
            "       person       0.98      0.28      0.43      2176\n",
            "          car       0.96      0.12      0.21       457\n",
            "        chair       0.87      0.09      0.16       304\n",
            "         book       1.00      0.00      0.01       283\n",
            "       bottle       0.71      0.03      0.05       187\n",
            "          cup       0.95      0.09      0.16       222\n",
            " dining table       0.71      0.12      0.20       127\n",
            "traffic light       1.00      0.03      0.05       116\n",
            "         bowl       0.70      0.06      0.11       119\n",
            "      handbag       0.00      0.00      0.00        95\n",
            "\n",
            "    micro avg       0.96      0.18      0.30      4086\n",
            "    macro avg       0.79      0.08      0.14      4086\n",
            " weighted avg       0.92      0.18      0.29      4086\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Get the 10 most common classes in the dataset\n",
        "counts = dataset.count_values(\"ground_truth.detections.label\")\n",
        "classes_top10 = sorted(counts, key=counts.get, reverse=True)[:10]\n",
        "\n",
        "# Print a classification report for the top-10 classes\n",
        "results_int8.print_report(classes=classes_top10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "TxZQUyQisvVf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d1255cb-5041-41f6-9679-c1f8184512a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.14640761435595998\n"
          ]
        }
      ],
      "source": [
        "print(results_int8.mAP())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "BVyGIyHhvEV8"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "TPhc0O04eoVy",
        "iO0PlwOdeoV1",
        "vtETueAEeoV1",
        "VosnnZROeoV2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "gpuClass": "standard",
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cb0acf31cc2c4a02907c9ba5c48a92e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9ffddea830b4b50b08037ed210b8e23",
              "IPY_MODEL_704273a4c24b494dafc67b3c0855b23b",
              "IPY_MODEL_9a08aab4898c4affba04c8e726077ad4"
            ],
            "layout": "IPY_MODEL_8d80c4f9dad148b49863eaecb061b55c"
          }
        },
        "c9ffddea830b4b50b08037ed210b8e23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c97c8e07ea34457b8cce65887a6e60c3",
            "placeholder": "​",
            "style": "IPY_MODEL_6c2db484430b4f3e9367094f374fe633",
            "value": "100%"
          }
        },
        "704273a4c24b494dafc67b3c0855b23b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32013ea49f9d433db844be6b1e7abe98",
            "max": 142594222,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f362539175f44249ce41f8f97b68568",
            "value": 142594222
          }
        },
        "9a08aab4898c4affba04c8e726077ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ccadd6cc2524212b6a198858997b63a",
            "placeholder": "​",
            "style": "IPY_MODEL_f379ac058c8e45a39853e4d6bddda309",
            "value": " 136M/136M [00:00&lt;00:00, 181MB/s]"
          }
        },
        "8d80c4f9dad148b49863eaecb061b55c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97c8e07ea34457b8cce65887a6e60c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c2db484430b4f3e9367094f374fe633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32013ea49f9d433db844be6b1e7abe98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1f362539175f44249ce41f8f97b68568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ccadd6cc2524212b6a198858997b63a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f379ac058c8e45a39853e4d6bddda309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}